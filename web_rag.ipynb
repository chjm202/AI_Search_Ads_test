{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbdf286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 正在抓取网页内容... ---\n",
      "--- 2. 正在进行文本分块 (Chunking) 和向量化 (Embedding)... ---\n",
      "成功创建 63 个文本块并存入向量数据库。\n",
      "--- 数据处理完成。 ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import bs4\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings \n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings \n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "URL_TO_SCRAPE = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
    "MODELSCOPE_ACCESS_TOKEN = \"ms-6634b7ff-46bc-4400-b9f0-d475b0890dab\" \n",
    "MODELSCOPE_BASE_URL = \"https://api-inference.modelscope.cn/v1/\"\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\" \n",
    "CHROMA_DB_PATH = \"./chroma_db_multilingual_minilm\" \n",
    "\n",
    "print(\"--- 1. 正在抓取网页内容... ---\")\n",
    "\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(URL_TO_SCRAPE,),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "print(\"--- 2. 正在进行文本分块 (Chunking) 和向量化 (Embedding)... ---\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_kwargs={'device': 'cuda'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=embeddings, \n",
    "    persist_directory=CHROMA_DB_PATH\n",
    ")\n",
    "\n",
    "print(f\"成功创建 {len(splits)} 个文本块并存入向量数据库。\")\n",
    "print(\"--- 数据处理完成。 ---\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6bf426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RAG 问答链构建完成。 ---\n",
      "问题 A: 什么是 Task Decomposition (任务分解)？它在 AI Agent 中有什么作用？\n",
      "\n",
      "--- 回答 A ---\n",
      "Task Decomposition（任务分解）是一种将复杂任务分解为更小、更简单步骤的方法。这种方法通过指导模型“逐步思考”来利用更多的计算资源，从而提高模型在复杂任务上的表现。任务分解将大型任务转换为多个可管理的任务，并提供了对模型思维过程的洞察。\n",
      "\n",
      "在 AI Agent 中，任务分解的作用是帮助代理了解需要执行的各个步骤，并提前进行规划。这使得复杂的任务可以被系统地处理，提高了任务执行的效率和准确性。通过将任务分解成更小的部分，AI Agent 可以更容易地管理和优化每个子任务的执行过程。\n",
      "----------------\n",
      "\n",
      "问题 B: 这篇博客的作者是谁？\n",
      "\n",
      "--- 回答 B ---\n",
      "这篇博客的作者是 Weng, Lilian。相关引用信息如下：\n",
      "```\n",
      "@article{weng2023agent,\n",
      "  title   = \"LLM-powered Autonomous Agents\",\n",
      "  author  = \"Weng, Lilian\",\n",
      "  journal = \"lilianweng.github.io\",\n",
      "  year    = \"2023\",\n",
      "  month   = \"Jun\",\n",
      "  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
      "}\n",
      "```\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"Qwen/Qwen2.5-Coder-32B-Instruct\", \n",
    "    base_url=MODELSCOPE_BASE_URL, \n",
    "    api_key=MODELSCOPE_ACCESS_TOKEN,\n",
    "    temperature=0\n",
    ") \n",
    "\n",
    "system_prompt = (\n",
    "    \"你是一位专业的 AI 助理。请根据提供的上下文 (Context) 来回答问题。如果上下文中没有信息，\"\n",
    "    \"请说明你无法找到答案。请用中文简洁明了地回答问题，并引用上下文中的关键信息。\"\n",
    "    \"\\n\\nContext: {context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "print(\"--- RAG 问答链构建完成。 ---\")\n",
    "\n",
    "question_a = \"什么是 Task Decomposition (任务分解)？它在 AI Agent 中有什么作用？\"\n",
    "print(f\"问题 A: {question_a}\")\n",
    "\n",
    "response_a = rag_chain.invoke({\"input\": question_a})\n",
    "print(\"\\n--- 回答 A ---\")\n",
    "print(response_a['answer'])\n",
    "print(\"----------------\\n\")\n",
    "\n",
    "\n",
    "question_b = \"这篇博客的作者是谁？\"\n",
    "print(f\"问题 B: {question_b}\")\n",
    "\n",
    "response_b = rag_chain.invoke({\"input\": question_b})\n",
    "print(\"\\n--- 回答 B ---\")\n",
    "print(response_b['answer'])\n",
    "print(\"----------------\\n\")\n",
    "\n",
    "\n",
    "# 删除本地 ChromaDB 文件夹\n",
    "# import shutil\n",
    "# shutil.rmtree(\"./chroma_db\")\n",
    "# print(\"本地数据库已清理。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
